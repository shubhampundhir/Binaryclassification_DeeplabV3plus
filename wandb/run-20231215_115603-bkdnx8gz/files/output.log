Device: cuda
Dataset: cityscapes, Train set: 13206, Val set: 1513
[!] Retrain
Epoch 1, Itrs 100/3000, Loss=0.686350
Epoch 1, Itrs 200/3000, Loss=0.615276
Epoch 1, Itrs 300/3000, Loss=0.657787
Epoch 1, Itrs 400/3000, Loss=0.708674
Epoch 1, Itrs 500/3000, Loss=0.669895
Epoch 1, Itrs 600/3000, Loss=0.622067
Epoch 1, Itrs 700/3000, Loss=0.662998
Traceback (most recent call last):
  File "main.py", line 367, in <module>
    main()
  File "main.py", line 318, in main
    optimizer.step()
  File "/home/shubhamp/anaconda3/envs/deeplearning/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/shubhamp/anaconda3/envs/deeplearning/lib/python3.8/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/shubhamp/anaconda3/envs/deeplearning/lib/python3.8/site-packages/torch/optim/optimizer.py", line 23, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/shubhamp/anaconda3/envs/deeplearning/lib/python3.8/site-packages/torch/optim/sgd.py", line 151, in step
    sgd(params_with_grad,
  File "/home/shubhamp/anaconda3/envs/deeplearning/lib/python3.8/site-packages/torch/optim/sgd.py", line 202, in sgd
    func(params,
  File "/home/shubhamp/anaconda3/envs/deeplearning/lib/python3.8/site-packages/torch/optim/sgd.py", line 245, in _single_tensor_sgd
    param.add_(d_p, alpha=-lr)
KeyboardInterrupt